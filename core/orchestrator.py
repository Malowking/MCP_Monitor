"""
ä¸»æµç¨‹ç¼–æ’å™¨ - æ•´åˆæ‰€æœ‰ç»„ä»¶å¤„ç†ç”¨æˆ·è¯·æ±‚
"""
import uuid
from typing import Dict, Any, List, Optional, AsyncGenerator
from datetime import datetime
from loguru import logger
import json

from database import DatabaseManager
from models.base_model import BaseModel, Message, ToolDefinition
from core import RAGRetriever, RiskAssessor, RuleEngine
from mcp_manager.service_manager import MCPServiceManager
from mcp_manager.tool_router import ToolRouter


class MCPOrchestrator:
    """MCPä¸»æµç¨‹ç¼–æ’å™¨"""

    def __init__(
        self,
        db_manager: DatabaseManager,
        model: BaseModel,
        config: Dict[str, Any]
    ):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨

        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨
            model: æ¨¡å‹å®ä¾‹
            config: å®Œæ•´é…ç½®
        """
        self.db = db_manager
        self.model = model
        self.config = config

        # åˆå§‹åŒ–å„ç»„ä»¶
        self.rag_retriever = RAGRetriever(db_manager, model, config)
        self.risk_assessor = RiskAssessor(config)
        self.rule_engine = RuleEngine(config)
        self.service_manager = MCPServiceManager(db_manager, config)
        self.tool_router = ToolRouter(db_manager, config)

        logger.info("MCP orchestrator initialized")

    async def start(self):
        """å¯åŠ¨ç¼–æ’å™¨"""
        await self.service_manager.start()
        logger.info("MCP orchestrator started")

    async def stop(self):
        """åœæ­¢ç¼–æ’å™¨"""
        await self.service_manager.stop()
        logger.info("MCP orchestrator stopped")

    async def process_query(
        self,
        user_id: str,
        user_question: str,
        conversation_context: Optional[List[Message]] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„ä¸»æµç¨‹

        æµç¨‹ï¼š
        1. å·¥å…·è·¯ç”± - é€‰æ‹©ç›¸å…³å·¥å…·
        2. æ¨¡å‹ç”Ÿæˆ - ç”Ÿæˆå·¥å…·è°ƒç”¨è‰æ¡ˆ
        3. RAGæ£€ç´¢ - æ£€ç´¢å†å²åé¦ˆ
        4. è§„åˆ™æ£€æŸ¥ - æ£€æŸ¥é»‘åå•å’Œè§„åˆ™
        5. é£é™©è¯„ä¼° - ç»¼åˆè¯„ä¼°é£é™©
        6. å†³ç­– - æ˜¯å¦éœ€è¦ç”¨æˆ·ç¡®è®¤
        7. ç”Ÿæˆå“åº” - åŒ…å«ç¡®è®¤æç¤ºå’Œå†å²å»ºè®®

        Args:
            user_id: ç”¨æˆ·ID
            user_question: ç”¨æˆ·é—®é¢˜
            conversation_context: å¯¹è¯ä¸Šä¸‹æ–‡

        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        request_id = str(uuid.uuid4())
        logger.info(f"Processing query {request_id}: {user_question[:50]}...")

        try:
            # 1. å·¥å…·è·¯ç”± - é€‰æ‹©ç›¸å…³å·¥å…·
            logger.debug("Step 1: Tool routing")
            routing_result = await self.tool_router.route_tools(
                user_question=user_question,
                user_id=user_id
            )

            available_tools = routing_result["total_tools"]
            logger.info(f"Routed {len(available_tools)} tools")

            # 2. æ¨¡å‹ç”Ÿæˆ - ç”Ÿæˆå·¥å…·è°ƒç”¨è‰æ¡ˆ
            logger.debug("Step 2: Model generation")
            messages = conversation_context or []
            messages.append(Message(role="user", content=user_question))

            # è½¬æ¢å·¥å…·æ ¼å¼
            tool_definitions = [
                ToolDefinition(
                    type="function",
                    function=tool.get("function") or tool
                )
                for tool in available_tools
            ]

            model_response = await self.model.generate(
                messages=messages,
                tools=tool_definitions if tool_definitions else None
            )

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if not model_response.tool_calls:
                logger.info("No tool calls in response")
                return {
                    "request_id": request_id,
                    "requires_confirmation": False,
                    "content": model_response.content,
                    "tool_calls": None
                }

            # å¤„ç†æ¯ä¸ªå·¥å…·è°ƒç”¨
            results = []
            for tool_call in model_response.tool_calls:
                result = await self._process_tool_call(
                    request_id=request_id,
                    user_id=user_id,
                    user_question=user_question,
                    tool_call=tool_call,
                    conversation_context=conversation_context
                )
                results.append(result)

            # å¦‚æœæœ‰ä»»ä½•ä¸€ä¸ªéœ€è¦ç¡®è®¤ï¼Œæ•´ä½“éœ€è¦ç¡®è®¤
            requires_confirmation = any(r["requires_confirmation"] for r in results)
            max_risk_score = max(r["risk_score"] for r in results)

            return {
                "request_id": request_id,
                "requires_confirmation": requires_confirmation,
                "risk_score": max_risk_score,
                "tool_calls": results,
                "content": model_response.content,
                "routing_info": {
                    "detected_intents": routing_result["detected_intents"],
                    "active_domains": routing_result["active_domains"],
                    "tool_count": len(available_tools)
                }
            }

        except Exception as e:
            logger.error(f"Error processing query {request_id}: {e}")
            raise

    async def _process_tool_call(
        self,
        request_id: str,
        user_id: str,
        user_question: str,
        tool_call: Dict[str, Any],
        conversation_context: Optional[List[Message]] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªå·¥å…·è°ƒç”¨

        Args:
            request_id: è¯·æ±‚ID
            user_id: ç”¨æˆ·ID
            user_question: ç”¨æˆ·é—®é¢˜
            tool_call: å·¥å…·è°ƒç”¨ä¿¡æ¯
            conversation_context: å¯¹è¯ä¸Šä¸‹æ–‡

        Returns:
            å¤„ç†ç»“æœ
        """
        tool_name = tool_call["function"]["name"]
        tool_parameters = eval(tool_call["function"]["arguments"])  # è§£æJSON

        logger.debug(f"Processing tool call: {tool_name}")

        # 3. RAGæ£€ç´¢ - æ£€ç´¢å†å²åé¦ˆ
        logger.debug("Step 3: RAG retrieval")
        similar_cases = await self.rag_retriever.retrieve_similar_cases(
            user_question=user_question,
            user_id=user_id
        )

        historical_analysis = self.rag_retriever.analyze_historical_feedback(similar_cases)

        # 4. è§„åˆ™æ£€æŸ¥ - æ£€æŸ¥é»‘åå•å’Œè§„åˆ™
        logger.debug("Step 4: Rule checking")
        rule_result = self.rule_engine.check_tool_call(
            tool_name=tool_name,
            tool_parameters=tool_parameters
        )

        # å¦‚æœè¢«é˜»æ­¢ï¼Œç›´æ¥è¿”å›
        if rule_result.get("blocked"):
            logger.warning(f"Tool call blocked: {tool_name}")
            return {
                "tool_call_id": tool_call["id"],
                "tool_name": tool_name,
                "tool_parameters": tool_parameters,
                "requires_confirmation": False,
                "blocked": True,
                "risk_score": 1.0,
                "messages": rule_result.get("messages", [])
            }

        # 5. é£é™©è¯„ä¼° - ç»¼åˆè¯„ä¼°é£é™©
        logger.debug("Step 5: Risk assessment")
        risk_result = self.risk_assessor.assess_tool_risk(
            tool_name=tool_name,
            tool_parameters=tool_parameters,
            historical_analysis=historical_analysis,
            rule_result=rule_result
        )

        # 6. å†³ç­– - æ˜¯å¦éœ€è¦ç”¨æˆ·ç¡®è®¤
        requires_confirmation = (
            risk_result["requires_confirmation"] or
            rule_result.get("force_confirm", False)
        )

        # 7. ç”Ÿæˆç¡®è®¤æ¶ˆæ¯ï¼ˆåŠ¨æ€promptæ³¨å…¥ï¼‰
        confirmation_message = self._generate_confirmation_message(
            tool_name=tool_name,
            tool_parameters=tool_parameters,
            risk_result=risk_result,
            historical_analysis=historical_analysis,
            rule_result=rule_result
        )

        # 8. å­˜å‚¨åˆ°æ•°æ®åº“
        history = await self.db.create_tool_call_history(
            request_id=request_id,
            user_id=user_id,
            user_question=user_question,
            tool_name=tool_name,
            tool_parameters=tool_parameters,
            risk_score=risk_result["risk_score"],
            requires_confirmation=requires_confirmation,
            matched_rules=[r.get("rule_id") for r in rule_result.get("matched_rules", [])],
            blacklist_hit=rule_result.get("blacklist_hit", False),
            confirmation_reason=confirmation_message,
            conversation_context=[m.model_dump() for m in conversation_context] if conversation_context else None,
            similar_history_ids=[c["history"].id for c in similar_cases]
        )

        # 9. å­˜å‚¨é—®é¢˜embedding
        vector_id = await self.rag_retriever.store_question_embedding(
            user_question=user_question,
            database_id=history.id
        )

        return {
            "tool_call_id": tool_call["id"],
            "tool_name": tool_name,
            "tool_parameters": tool_parameters,
            "requires_confirmation": requires_confirmation,
            "blocked": False,
            "risk_score": risk_result["risk_score"],
            "risk_level": risk_result["risk_level"],
            "confirmation_message": confirmation_message,
            "risk_reasons": risk_result["reasons"],
            "historical_insights": historical_analysis.get("common_patterns", []),
            "similar_case_count": len(similar_cases)
        }

    def _generate_confirmation_message(
        self,
        tool_name: str,
        tool_parameters: Dict[str, Any],
        risk_result: Dict[str, Any],
        historical_analysis: Dict[str, Any],
        rule_result: Dict[str, Any]
    ) -> str:
        """
        ç”Ÿæˆç¡®è®¤æ¶ˆæ¯ï¼ˆåŠ¨æ€promptæ³¨å…¥ï¼‰

        Args:
            tool_name: å·¥å…·åç§°
            tool_parameters: å·¥å…·å‚æ•°
            risk_result: é£é™©è¯„ä¼°ç»“æœ
            historical_analysis: å†å²åˆ†æ
            rule_result: è§„åˆ™æ£€æŸ¥ç»“æœ

        Returns:
            ç¡®è®¤æ¶ˆæ¯
        """
        message_parts = []

        # åŸºç¡€ä¿¡æ¯
        message_parts.append(f"å‡†å¤‡è°ƒç”¨å·¥å…·: {tool_name}")

        # å‚æ•°ä¿¡æ¯
        param_str = ", ".join(f"{k}={v}" for k, v in tool_parameters.items())
        message_parts.append(f"å‚æ•°: {param_str}")

        # é£é™©ç­‰çº§
        risk_level = risk_result["risk_level"]
        risk_emoji = {"low": "ğŸŸ¢", "medium": "ğŸŸ¡", "high": "ğŸ”´"}.get(risk_level, "âšª")
        message_parts.append(f"é£é™©ç­‰çº§: {risk_emoji} {risk_level.upper()}")

        # é£é™©åŸå› 
        if risk_result.get("reasons"):
            message_parts.append("é£é™©åˆ†æ:")
            for reason in risk_result["reasons"]:
                message_parts.append(f"  - {reason}")

        # å†å²åé¦ˆï¼ˆåŠ¨æ€promptæ³¨å…¥ï¼‰
        if historical_analysis.get("has_history"):
            message_parts.append(f"\næ ¹æ®æ‚¨è¿‡å»çš„ä½¿ç”¨è®°å½•:")

            if historical_analysis.get("common_patterns"):
                for pattern in historical_analysis["common_patterns"]:
                    message_parts.append(f"  - {pattern}")

            if historical_analysis.get("user_preferences"):
                for pref in historical_analysis["user_preferences"]:
                    message_parts.append(f"  - {pref}")

        # è§„åˆ™æç¤º
        if rule_result.get("matched_rules"):
            message_parts.append("\nè§¦å‘çš„å®‰å…¨è§„åˆ™:")
            for rule in rule_result["matched_rules"][:2]:
                message_parts.append(f"  - {rule.get('name', 'Unknown')}")

        message_parts.append("\næ˜¯å¦ç¡®è®¤æ‰§è¡Œæ­¤æ“ä½œï¼Ÿ")

        return "\n".join(message_parts)

    async def confirm_tool_call(
        self,
        request_id: str,
        user_id: str,
        confirmed: bool,
        feedback: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ç”¨æˆ·ç¡®è®¤å·¥å…·è°ƒç”¨

        Args:
            request_id: è¯·æ±‚ID
            user_id: ç”¨æˆ·ID
            confirmed: æ˜¯å¦ç¡®è®¤
            feedback: ç”¨æˆ·åé¦ˆ

        Returns:
            ç¡®è®¤ç»“æœ
        """
        logger.info(f"Tool call {request_id} confirmed: {confirmed}")

        # æ›´æ–°æ•°æ®åº“
        success = await self.db.update_tool_call_confirmation(
            request_id=request_id,
            user_confirmed=confirmed,
            user_feedback=feedback
        )

        if not success:
            logger.error(f"Failed to update confirmation for {request_id}")
            return {"success": False, "message": "Request not found"}

        if confirmed:
            return {
                "success": True,
                "message": "å·¥å…·è°ƒç”¨å·²ç¡®è®¤ï¼Œå¯ä»¥æ‰§è¡Œ",
                "action": "execute"
            }
        else:
            return {
                "success": True,
                "message": "å·¥å…·è°ƒç”¨å·²å–æ¶ˆ",
                "action": "cancel"
            }

    async def record_execution_result(
        self,
        request_id: str,
        execution_success: bool,
        execution_result: Optional[Dict] = None
    ):
        """
        è®°å½•å·¥å…·æ‰§è¡Œç»“æœ

        Args:
            request_id: è¯·æ±‚ID
            execution_success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            execution_result: æ‰§è¡Œç»“æœ
        """
        await self.db.update_tool_call_execution(
            request_id=request_id,
            execution_success=execution_success,
            execution_result=execution_result
        )

        logger.info(f"Recorded execution result for {request_id}: {execution_success}")

    async def process_query_stream(
        self,
        user_id: str,
        user_question: str,
        conversation_context: Optional[List[Message]] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢

        Args:
            user_id: ç”¨æˆ·ID
            user_question: ç”¨æˆ·é—®é¢˜
            conversation_context: å¯¹è¯ä¸Šä¸‹æ–‡

        Yields:
            Dict[str, Any]: æµå¼å“åº”æ•°æ®
        """
        request_id = str(uuid.uuid4())
        logger.info(f"Processing stream query {request_id}: {user_question[:50]}...")

        try:
            # æ­¥éª¤1: å·¥å…·è·¯ç”±
            yield {
                'type': 'progress',
                'step': 'tool_routing',
                'message': 'ğŸ” æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·...',
                'request_id': request_id
            }

            routing_result = await self.tool_router.route_tools(
                user_question=user_question,
                user_id=user_id
            )

            available_tools = routing_result["total_tools"]
            yield {
                'type': 'routing_complete',
                'message': f'âœ… å‘ç° {len(available_tools)} ä¸ªç›¸å…³å·¥å…·',
                'tools_count': len(available_tools),
                'detected_intents': routing_result["detected_intents"],
                'active_domains': routing_result["active_domains"]
            }

            # æ­¥éª¤2: å‡†å¤‡æ¨¡å‹ç”Ÿæˆ
            yield {
                'type': 'progress',
                'step': 'model_generation',
                'message': 'ğŸ¤– AIæ­£åœ¨åˆ†æå¹¶ç”Ÿæˆå›å¤...'
            }

            messages = conversation_context or []
            messages.append(Message(role="user", content=user_question))

            # è½¬æ¢å·¥å…·æ ¼å¼
            tool_definitions = [
                ToolDefinition(
                    type="function",
                    function=tool.get("function") or tool
                )
                for tool in available_tools
            ]

            # æ£€æŸ¥æ˜¯å¦æ”¯æŒæµå¼ç”Ÿæˆ
            if hasattr(self.model, 'generate_stream'):
                # æµå¼æ¨¡å‹ç”Ÿæˆ
                content_buffer = ""
                async for chunk in self.model.generate_stream(
                    messages=messages,
                    tools=tool_definitions if tool_definitions else None
                ):
                    content_buffer += chunk
                    yield {
                        'type': 'model_stream',
                        'chunk': chunk,
                        'content': content_buffer
                    }

                # ä½¿ç”¨ç¼“å†²çš„å†…å®¹æ¥æ¨¡æ‹Ÿå®Œæ•´å“åº”
                # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è§£æå·¥å…·è°ƒç”¨ï¼Œå®é™…å®ç°å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
                model_response = await self.model.generate(
                    messages=messages,
                    tools=tool_definitions if tool_definitions else None
                )

                yield {
                    'type': 'model_complete',
                    'content': model_response.content,
                    'has_tool_calls': model_response.tool_calls is not None
                }
            else:
                # éæµå¼æ¨¡å‹ç”Ÿæˆ
                model_response = await self.model.generate(
                    messages=messages,
                    tools=tool_definitions if tool_definitions else None
                )

                yield {
                    'type': 'model_complete',
                    'content': model_response.content,
                    'has_tool_calls': model_response.tool_calls is not None
                }

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if not model_response.tool_calls:
                yield {
                    'type': 'complete',
                    'request_id': request_id,
                    'requires_confirmation': False,
                    'content': model_response.content,
                    'message': 'âœ… å¤„ç†å®Œæˆï¼Œæ— éœ€å·¥å…·è°ƒç”¨'
                }
                return

            # æ­¥éª¤3: å¤„ç†å·¥å…·è°ƒç”¨
            yield {
                'type': 'progress',
                'step': 'tool_processing',
                'message': f'ğŸ”§ æ­£åœ¨å¤„ç† {len(model_response.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨...'
            }

            results = []
            for i, tool_call in enumerate(model_response.tool_calls):
                yield {
                    'type': 'tool_analysis',
                    'tool_index': i + 1,
                    'total_tools': len(model_response.tool_calls),
                    'tool_name': tool_call["function"]["name"],
                    'message': f'ğŸ› ï¸ åˆ†æå·¥å…·è°ƒç”¨ {i + 1}/{len(model_response.tool_calls)}: {tool_call["function"]["name"]}'
                }

                # æµå¼å¤„ç†å•ä¸ªå·¥å…·è°ƒç”¨
                async for chunk in self._process_tool_call_stream(
                    request_id=request_id,
                    user_id=user_id,
                    user_question=user_question,
                    tool_call=tool_call,
                    conversation_context=conversation_context,
                    tool_index=i + 1
                ):
                    yield chunk

                # è·å–å¤„ç†ç»“æœ
                result = await self._process_tool_call(
                    request_id=request_id,
                    user_id=user_id,
                    user_question=user_question,
                    tool_call=tool_call,
                    conversation_context=conversation_context
                )
                results.append(result)

            # æœ€ç»ˆç»“æœ
            requires_confirmation = any(r["requires_confirmation"] for r in results)
            max_risk_score = max(r["risk_score"] for r in results)

            yield {
                'type': 'complete',
                'request_id': request_id,
                'requires_confirmation': requires_confirmation,
                'risk_score': max_risk_score,
                'tool_calls': results,
                'content': model_response.content,
                'routing_info': {
                    "detected_intents": routing_result["detected_intents"],
                    "active_domains": routing_result["active_domains"],
                    "tool_count": len(available_tools)
                },
                'message': 'ğŸ‰ å¤„ç†å®Œæˆï¼' if not requires_confirmation else 'âš ï¸ è¯·ç¡®è®¤æ˜¯å¦æ‰§è¡Œé«˜é£é™©æ“ä½œ'
            }

        except Exception as e:
            logger.error(f"Error in stream processing {request_id}: {e}")
            yield {
                'type': 'error',
                'request_id': request_id,
                'error': str(e),
                'message': f'âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}'
            }

    async def _process_tool_call_stream(
        self,
        request_id: str,
        user_id: str,
        user_question: str,
        tool_call: Dict[str, Any],
        conversation_context: Optional[List[Message]] = None,
        tool_index: int = 1
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¤„ç†å•ä¸ªå·¥å…·è°ƒç”¨

        Args:
            request_id: è¯·æ±‚ID
            user_id: ç”¨æˆ·ID
            user_question: ç”¨æˆ·é—®é¢˜
            tool_call: å·¥å…·è°ƒç”¨ä¿¡æ¯
            conversation_context: å¯¹è¯ä¸Šä¸‹æ–‡
            tool_index: å·¥å…·ç´¢å¼•

        Yields:
            Dict[str, Any]: æµå¼å¤„ç†æ•°æ®
        """
        tool_name = tool_call["function"]["name"]
        try:
            tool_parameters = eval(tool_call["function"]["arguments"])  # è§£æJSON
        except:
            tool_parameters = {}

        # RAGæ£€ç´¢
        yield {
            'type': 'rag_retrieval',
            'tool_index': tool_index,
            'tool_name': tool_name,
            'message': 'ğŸ“š æ£€ç´¢ç›¸ä¼¼å†å²æ¡ˆä¾‹...'
        }

        similar_cases = await self.rag_retriever.retrieve_similar_cases(
            user_question=user_question,
            user_id=user_id
        )

        historical_analysis = self.rag_retriever.analyze_historical_feedback(similar_cases)

        yield {
            'type': 'rag_complete',
            'tool_index': tool_index,
            'similar_cases_count': len(similar_cases),
            'has_history': historical_analysis.get("has_history", False),
            'message': f'âœ… æ‰¾åˆ° {len(similar_cases)} ä¸ªç›¸ä¼¼æ¡ˆä¾‹'
        }

        # è§„åˆ™æ£€æŸ¥
        yield {
            'type': 'rule_check',
            'tool_index': tool_index,
            'tool_name': tool_name,
            'message': 'ğŸ›¡ï¸ æ£€æŸ¥å®‰å…¨è§„åˆ™...'
        }

        rule_result = self.rule_engine.check_tool_call(
            tool_name=tool_name,
            tool_parameters=tool_parameters
        )

        if rule_result.get("blocked"):
            yield {
                'type': 'rule_blocked',
                'tool_index': tool_index,
                'tool_name': tool_name,
                'messages': rule_result.get("messages", []),
                'message': 'âŒ æ“ä½œè¢«å®‰å…¨è§„åˆ™é˜»æ­¢'
            }
            return

        yield {
            'type': 'rule_complete',
            'tool_index': tool_index,
            'matched_rules': len(rule_result.get("matched_rules", [])),
            'message': 'âœ… å®‰å…¨è§„åˆ™æ£€æŸ¥é€šè¿‡'
        }

        # é£é™©è¯„ä¼°
        yield {
            'type': 'risk_assessment',
            'tool_index': tool_index,
            'tool_name': tool_name,
            'message': 'âš–ï¸ è¯„ä¼°æ“ä½œé£é™©...'
        }

        risk_result = self.risk_assessor.assess_tool_risk(
            tool_name=tool_name,
            tool_parameters=tool_parameters,
            historical_analysis=historical_analysis,
            rule_result=rule_result
        )

        requires_confirmation = (
            risk_result["requires_confirmation"] or
            rule_result.get("force_confirm", False)
        )

        risk_level = risk_result["risk_level"]
        risk_emoji = {"low": "ğŸŸ¢", "medium": "ğŸŸ¡", "high": "ğŸ”´"}.get(risk_level, "âšª")

        yield {
            'type': 'risk_complete',
            'tool_index': tool_index,
            'tool_name': tool_name,
            'tool_parameters': tool_parameters,
            'risk_score': risk_result["risk_score"],
            'risk_level': risk_level,
            'requires_confirmation': requires_confirmation,
            'risk_reasons': risk_result["reasons"],
            'message': f'{risk_emoji} é£é™©è¯„ä¼°å®Œæˆ: {risk_level.upper()} ({risk_result["risk_score"]:.2f})'
        }

        if requires_confirmation:
            # ç”Ÿæˆç¡®è®¤æ¶ˆæ¯
            confirmation_message = self._generate_confirmation_message(
                tool_name=tool_name,
                tool_parameters=tool_parameters,
                risk_result=risk_result,
                historical_analysis=historical_analysis,
                rule_result=rule_result
            )

            yield {
                'type': 'confirmation_required',
                'tool_index': tool_index,
                'tool_name': tool_name,
                'confirmation_message': confirmation_message,
                'message': 'âš ï¸ éœ€è¦ç”¨æˆ·ç¡®è®¤'
            }
